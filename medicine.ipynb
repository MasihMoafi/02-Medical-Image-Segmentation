{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Dropout, Conv2DTranspose, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the datasets\n",
    "img_dir = r'C:\\Users\\user\\Desktop\\abdominal data\\abdominal_US\\abdominal_US\\AUS\\images\\train'\n",
    "mask_dir = r'C:\\Users\\user\\Desktop\\abdominal data\\abdominal_US\\abdominal_US\\AUS\\annotations\\train'\n",
    "\n",
    "\n",
    "\n",
    "# Load and preprocess the training images.\n",
    "img_names = os.listdir(img_dir)\n",
    "imgs = [Image.open(os.path.join(img_dir, img_name)) for img_name in img_names]\n",
    "X = np.array([np.array(img.resize((464, 464))) for img in imgs])\n",
    "X = X / 255.0  # Normalize the images to [0, 1] range.\n",
    "\n",
    "# Define a mapping from RGB values to class labels.\n",
    "colors_to_labels = {\n",
    "    (255, 255, 0): 0,  # Yellow\n",
    "    (255, 0, 255): 1,  # Red\n",
    "    (100, 0, 100): 2,  # Darker red\n",
    "    (0, 255, 0): 3  # Green\n",
    "}\n",
    "\n",
    "# Load, preprocess, and encode the masks.\n",
    "mask_names = os.listdir(mask_dir)\n",
    "masks = [Image.open(os.path.join(mask_dir, mask_name)) for mask_name in mask_names]\n",
    "masks = [mask.resize((464, 464)) for mask in masks] \n",
    "Y = np.empty((len(masks), 464, 464, len(colors_to_labels)))\n",
    "\n",
    "for i, mask in enumerate(masks):\n",
    "    mask_array = np.array(mask)\n",
    "    for j, (color, label) in enumerate(colors_to_labels.items()):\n",
    "        Y[i, :, :, j] = np.all(mask_array == np.array(color).reshape(1, 1, 3), axis=2)\n",
    "\n",
    "# Split the data into a training set and a validation set.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the U-Net model.\n",
    "inputs = Input((464, 464, 3))\n",
    "conv1 = Conv2D(64, 4, activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(64, 4, activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(128, 4, activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(128, 4, activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = Conv2D(256, 4, activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(256, 4, activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = Conv2D(512, 4, activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(512, 4, activation='relu', padding='same')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "conv5 = Conv2D(1024, 4, activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(1024, 4, activation='relu', padding='same')(conv5)\n",
    "drop5 = Dropout(0.5)(conv5)\n",
    "up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "merge6 = concatenate([drop4, up6], axis=3)\n",
    "conv6 = Conv2D(512, 4, activation='relu', padding='same')(merge6)\n",
    "conv6 = Conv2D(512, 4, activation='relu', padding='same')(conv6)\n",
    "up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "merge7 = concatenate([conv3, up7], axis=3)\n",
    "conv7 = Conv2D(256, 4, activation='relu', padding='same')(merge7)\n",
    "conv7 = Conv2D(256, 4, activation='relu', padding='same')(conv7)\n",
    "up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "merge8 = concatenate([conv2, up8], axis=3)\n",
    "conv8 = Conv2D(128, 4, activation='relu', padding='same')(merge8)\n",
    "conv8 = Conv2D(128, 4, activation='relu', padding='same')(conv8)\n",
    "up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "merge9 = concatenate([conv1, up9], axis=3)\n",
    "conv9 = Conv2D(64, 4, activation='relu', padding='same')(merge9)\n",
    "conv9 = Conv2D(64, 4, activation='relu', padding='same')(conv9)\n",
    "conv9 = Conv2D(64,4, activation='relu', padding='same')(conv9)\n",
    "conv10 = Conv2D(4, 1, activation='softmax')(conv9)\n",
    "\n",
    "model = Model(inputs, conv10)\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-4), loss = 'categorical_crossentropy')\n",
    "\n",
    "# Fit the model to the training data.\n",
    "model.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=4, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d15a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "img_dir = r'C:\\Users\\user\\Desktop\\New folder (3)\\abdominal_US\\abdominal_US\\AUS\\images\\train'\n",
    "mask_dir = r'C:\\Users\\user\\Desktop\\New folder (3)\\abdominal_US\\abdominal_US\\AUS\\annotations\\train'\n",
    "\n",
    "image_list = [os.path.join(img_dir, img_name) for img_name in os.listdir(img_dir)]\n",
    "mask_list = [os.path.join(mask_dir, mask_name) for mask_name in os.listdir(mask_dir)]\n",
    "\n",
    "image_list_ds = tf.data.Dataset.from_tensor_slices(image_list)\n",
    "mask_list_ds = tf.data.Dataset.from_tensor_slices(mask_list)\n",
    "\n",
    "# Ensure the lists are in the same order\n",
    "image_list_ds = tf.data.Dataset.from_tensor_slices(image_list)\n",
    "mask_list_ds = tf.data.Dataset.from_tensor_slices(mask_list)\n",
    "\n",
    "# Create a Dataset of (image, mask) pairs\n",
    "dataset = tf.data.Dataset.zip((image_list_ds, mask_list_ds))\n",
    "\n",
    "def process_path(image_path, mask_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=3)\n",
    "    \n",
    "    return img, mask\n",
    "\n",
    "def preprocess(image, mask):\n",
    "    input_image = tf.image.resize(image, (464, 464), method='nearest')\n",
    "    input_mask = tf.image.resize(mask, (464, 464), method='nearest')\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "dataset = dataset.map(process_path)\n",
    "dataset = dataset.map(preprocess)\n",
    "\n",
    "# Verify the preprocessing\n",
    "for image, mask in dataset.take(1):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Image')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask)\n",
    "    plt.title('Mask')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D\n",
    "#defining the encoding part of our U-net\n",
    "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
    "    \"\"\"\n",
    "    Convolutional downsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        inputs -- Input tensor\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        dropout_prob -- Dropout probability\n",
    "        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
    "    Returns: \n",
    "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
    "    \"\"\"\n",
    "\n",
    "    conv = Conv2D(n_filters, \n",
    "                  4,     \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal')(inputs)\n",
    "    conv = Conv2D(n_filters,\n",
    "                  4,   \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal')(conv)\n",
    "    \n",
    "    # if dropout_prob > 0 add a dropout layer, with the variable dropout_prob as parameter\n",
    "    if dropout_prob > 0:\n",
    "         conv = Dropout(dropout_prob)(conv)\n",
    "         \n",
    "    # if max_pooling is True add a MaxPooling2D with 2x2 pool_size\n",
    "    if max_pooling:\n",
    "        next_layer = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "        \n",
    "    else:\n",
    "        next_layer = conv\n",
    "        \n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce49410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining our decoding part of our U-net\n",
    "from tensorflow.keras.layers import Conv2DTranspose, concatenate\n",
    "\n",
    "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
    "    \"\"\"\n",
    "    Convolutional upsampling block\n",
    "    \n",
    "    Arguments:\n",
    "        expansive_input -- Input tensor from previous layer\n",
    "        contractive_input -- Input tensor from previous skip layer\n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "    Returns: \n",
    "        conv -- Tensor output\n",
    "    \"\"\"\n",
    "    \n",
    "    up = Conv2DTranspose(\n",
    "                 n_filters,    \n",
    "                 (4, 4),   \n",
    "                 strides=(2, 2),\n",
    "                 padding='same')(expansive_input)\n",
    "    merge = concatenate([up, contractive_input], axis=3)\n",
    "    conv = Conv2D(n_filters,  \n",
    "                 (4, 4),    \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(merge)\n",
    "    conv = Conv2D(n_filters,  \n",
    "                 (4, 4),  \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(conv)\n",
    "    \n",
    "    return conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96718962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unet_model(input_size=(464, 464, 3), n_filters=32, n_classes=23):\n",
    "    \"\"\"\n",
    "    Unet model\n",
    "    \n",
    "    Arguments:\n",
    "        input_size -- Input shape \n",
    "        n_filters -- Number of filters for the convolutional layers\n",
    "        n_classes -- Number of output classes\n",
    "    Returns: \n",
    "        model -- tf.keras.Model\n",
    "    \"\"\"\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    cblock1 = conv_block(inputs, n_filters)\n",
    "    cblock2 = conv_block(cblock1[0], n_filters*2)\n",
    "    cblock3 = conv_block(cblock2[0], n_filters*4)\n",
    "    cblock4 = conv_block(cblock3[0], n_filters*8, dropout_prob=0.3) \n",
    "    cblock5 = conv_block(cblock4[0], n_filters*16, dropout_prob=0.3, max_pooling=False) \n",
    "    ublock6 = upsampling_block(cblock5[0], cblock4[1],  n_filters*8)\n",
    "    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)\n",
    "    ublock8 = upsampling_block(ublock7, cblock2[1],  n_filters*2)\n",
    "    ublock9 = upsampling_block(ublock8, cblock1[1],  n_filters)\n",
    "\n",
    "    conv9 = Conv2D(n_filters,\n",
    "                 (3, 3),\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(ublock9)\n",
    "\n",
    "    conv10 = Conv2D(n_classes, (1, 1), padding='same')(conv9)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model\n",
    "img_height = 464\n",
    "img_width = 464\n",
    "num_channels = 3\n",
    "\n",
    "unet = unet_model((img_height, img_width, num_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fba9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11636c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BUFFER_SIZE = 500\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Preparing the dataset for training by caching, shuffling, and batching\n",
    "train_dataset = dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# Compile the model\n",
    "unet.compile(optimizer=Adam(), \n",
    "             loss=SparseCategoricalCrossentropy(from_logits=True), \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_history = unet.fit(train_dataset, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e03c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Environment",
   "language": "python",
   "name": "new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
